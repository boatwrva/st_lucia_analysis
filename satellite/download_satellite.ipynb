{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d98e365-ca80-4c4f-a933-991be483add0",
   "metadata": {},
   "source": [
    "## download satellite ocean color files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85fee6a-2080-4772-8586-1901a1ad8f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v] [--filelist FILELIST]\n",
      "                             [--http_manifest HTTP_MANIFEST] [--odir ODIR]\n",
      "                             [--uncompress] [--checksum] [--failed FAILED]\n",
      "                             [--appkey APPKEY] [--force]\n",
      "                             [filename]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vboatwright/python_environments/sio/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "#\n",
    "# A valid .netrc file in the user home ($HOME) directory, or a valid appkey is required.\n",
    "#\n",
    "#   Example .netrc:\n",
    "#    machine urs.earthdata.nasa.gov login USERNAME password PASSWD\n",
    "#\n",
    "#   An appkey can be obtained from:\n",
    "#    https://oceandata.sci.gsfc.nasa.gov/appkey/\n",
    "#\n",
    "# from obdaac_download import httpdl\n",
    "#\n",
    "# server = 'oceandata.sci.gsfc.nasa.gov'\n",
    "# request = '/ob/getfile/T2017004001500.L1A_LAC.bz2'\n",
    "#\n",
    "# status = httpdl(server, request, uncompress=True)\n",
    "#\n",
    "import argparse\n",
    "import hashlib\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "import logging\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import textwrap\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "\n",
    "DEFAULT_CHUNK_SIZE = 131072\n",
    "BLOCKSIZE = 65536\n",
    "\n",
    "# requests session object used to keep connections around\n",
    "obpgSession = None\n",
    "\n",
    "def getSession(verbose=0, ntries=5):\n",
    "    global obpgSession\n",
    "\n",
    "    if not obpgSession:\n",
    "        # turn on debug statements for requests\n",
    "        if verbose > 1:\n",
    "            print(\"Session started\")\n",
    "            logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "        obpgSession = requests.Session()\n",
    "        obpgSession.mount('https://', HTTPAdapter(max_retries=ntries))\n",
    "\n",
    "    else:\n",
    "        if verbose > 1:\n",
    "            print(\"Reusing existing session\")\n",
    "\n",
    "    return obpgSession\n",
    "\n",
    "def isRequestAuthFailure(req) :\n",
    "    ctype = req.headers.get('Content-Type')\n",
    "    if ctype and ctype.startswith('text/html'):\n",
    "        if \"<title>Earthdata Login</title>\" in req.text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def httpdl(server, request, localpath='.', outputfilename=None, ntries=5,\n",
    "           uncompress=False, timeout=30., verbose=0, force_download=False,\n",
    "           chunk_size=DEFAULT_CHUNK_SIZE):\n",
    "\n",
    "    status = 0\n",
    "    urlStr = 'https://' + server + request\n",
    "\n",
    "    global obpgSession\n",
    "    localpath = Path(localpath)\n",
    "    getSession(verbose=verbose, ntries=ntries)\n",
    "\n",
    "    modified_since = None\n",
    "    headers = {}\n",
    "\n",
    "    if not force_download:\n",
    "        if outputfilename:\n",
    "            ofile = localpath / outputfilename\n",
    "            modified_since = get_file_time(ofile)\n",
    "        else:\n",
    "            rpath = Path(request.rstrip())\n",
    "            if 'requested_files' in request:\n",
    "                rpath = Path(request.rstrip().split('?')[0])\n",
    "            ofile = localpath / rpath.name\n",
    "            if re.search(r'(?<=\\?)(\\w+)', ofile.name):\n",
    "                ofile = Path(ofile.name.split('?')[0])\n",
    "\n",
    "            modified_since = get_file_time(ofile)\n",
    "\n",
    "        if modified_since:\n",
    "            headers = {\"If-Modified-Since\":modified_since.strftime(\"%a, %d %b %Y %H:%M:%S GMT\")}\n",
    "\n",
    "    with obpgSession.get(urlStr, stream=True, timeout=timeout, headers=headers) as req:\n",
    "\n",
    "        if req.status_code != 200:\n",
    "            status = req.status_code\n",
    "        elif isRequestAuthFailure(req):\n",
    "            status = 401\n",
    "        else:\n",
    "            if not Path.exists(localpath):\n",
    "                os.umask(0o02)\n",
    "                Path.mkdir(localpath, mode=0o2775, parents=True)\n",
    "\n",
    "            if not outputfilename:\n",
    "                cd = req.headers.get('Content-Disposition')\n",
    "                if cd:\n",
    "                    outputfilename = re.findall(\"filename=(.+)\", cd)[0]\n",
    "                else:\n",
    "                    outputfilename = urlStr.split('/')[-1]\n",
    "\n",
    "            ofile = localpath / outputfilename\n",
    "\n",
    "            # This is here just in case we didn't get a 304 when we should have...\n",
    "            download = True\n",
    "            if 'last-modified' in req.headers:\n",
    "                remote_lmt = req.headers['last-modified']\n",
    "                remote_ftime = datetime.strptime(remote_lmt, \"%a, %d %b %Y %H:%M:%S GMT\").replace(tzinfo=None)\n",
    "                if modified_since and not force_download:\n",
    "                    if (remote_ftime - modified_since).total_seconds() < 0:\n",
    "                        download = False\n",
    "                        if verbose:\n",
    "                            print(\"Skipping download of %s\" % outputfilename)\n",
    "\n",
    "            if download:\n",
    "                total_length = req.headers.get('content-length')\n",
    "                length_downloaded = 0\n",
    "                total_length = int(total_length)\n",
    "                if verbose >0:\n",
    "                    print(\"Downloading %s (%8.2f MBs)\" % (outputfilename,total_length /1024/1024))\n",
    "\n",
    "                with open(ofile, 'wb') as fd:\n",
    "\n",
    "                    for chunk in req.iter_content(chunk_size=chunk_size):\n",
    "                        if chunk: # filter out keep-alive new chunks\n",
    "                            length_downloaded += len(chunk)\n",
    "                            fd.write(chunk)\n",
    "                            if verbose > 0:\n",
    "                                percent_done = int(50 * length_downloaded / total_length)\n",
    "                                sys.stdout.write(\"\\r[%s%s]\" % ('=' * percent_done, ' ' * (50-percent_done)))\n",
    "                                sys.stdout.flush()\n",
    "\n",
    "                if uncompress:\n",
    "                    if ofile.suffix in {'.Z', '.gz', '.bz2'}:\n",
    "                        if verbose:\n",
    "                            print(\"\\nUncompressing {}\".format(ofile))\n",
    "                        compressStatus = uncompressFile(ofile)\n",
    "                        if compressStatus:\n",
    "                            status = compressStatus\n",
    "                else:\n",
    "                    status = 0\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"\\n...Done\")\n",
    "\n",
    "    return status\n",
    "\n",
    "\n",
    "def uncompressFile(compressed_file):\n",
    "    \"\"\"\n",
    "    uncompress file\n",
    "    compression methods:\n",
    "        bzip2\n",
    "        gzip\n",
    "        UNIX compress\n",
    "    \"\"\"\n",
    "\n",
    "    compProg = {\".gz\": \"gunzip -f \", \".Z\": \"gunzip -f \", \".bz2\": \"bunzip2 -f \"}\n",
    "    exten = Path(compressed_file).suffix\n",
    "    unzip = compProg[exten]\n",
    "    p = subprocess.Popen(unzip + str(compressed_file.resolve()), shell=True)\n",
    "    status = os.waitpid(p.pid, 0)[1]\n",
    "    if status:\n",
    "        print(\"Warning! Unable to decompress %s\" % compressed_file)\n",
    "        return status\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_file_time(localFile):\n",
    "    ftime = None\n",
    "    localFile = Path(localFile)\n",
    "    if not Path.is_file(localFile):\n",
    "        while localFile.suffix in {'.Z', '.gz', '.bz2'}:\n",
    "            localFile = localFile.with_suffix('')\n",
    "\n",
    "    if Path.is_file(localFile):\n",
    "        ftime = datetime.fromtimestamp(localFile.stat().st_mtime)\n",
    "\n",
    "    return ftime\n",
    "\n",
    "def compare_checksum(filepath,checksum):\n",
    "    hasher = hashlib.sha1()\n",
    "    with open(filepath, 'rb') as afile:\n",
    "        buf = afile.read(BLOCKSIZE)\n",
    "        while len(buf) > 0:\n",
    "            hasher.update(buf)\n",
    "            buf = afile.read(BLOCKSIZE)\n",
    "    \n",
    "    if hasher.hexdigest() == checksum:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def retrieveURL(request,localpath='.', uncompress=False, verbose=0,force_download=False, appkey=False, checksum=False):\n",
    "    if args.verbose:\n",
    "        print(\"Retrieving %s\" % request.rstrip())\n",
    "\n",
    "    server = \"oceandata.sci.gsfc.nasa.gov\"\n",
    "    parsedRequest = urlparse(request)\n",
    "    netpath = parsedRequest.path\n",
    "\n",
    "    if parsedRequest.netloc:\n",
    "        server = parsedRequest.netloc\n",
    "    else:\n",
    "        if not re.match(\".*getfile\",netpath):\n",
    "            netpath = '/ob/getfile/' + netpath\n",
    "\n",
    "    joiner = '?'\n",
    "    if (re.match(\".*getfile\",netpath)) and appkey:\n",
    "        netpath = netpath + joiner +'appkey=' + appkey\n",
    "        joiner = '&'\n",
    "\n",
    "    if parsedRequest.query:\n",
    "        netpath = netpath + joiner + parsedRequest.query\n",
    "\n",
    "    status = httpdl(server, netpath, localpath=localpath, uncompress=uncompress, verbose=verbose,force_download=force_download)\n",
    "    \n",
    "    if checksum and not uncompress:\n",
    "        cksumURL = 'https://'+server + '/checkdata/' + parsedRequest.path\n",
    "        dnldfile = localpath / parsedRequest.path\n",
    "        if compare_checksum(dnldfile,requests.get(cksumURL).text):\n",
    "            print(\"The file %s failed checksum test\" % parsedRequest.path)\n",
    "            status = 1\n",
    "\n",
    "    return status\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parse command line\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawTextHelpFormatter,\n",
    "        description='Download files archived at the OB.DAAC',\n",
    "        epilog=textwrap.dedent('''\n",
    "Provide one of either filename, --filelist or --http_manifest.\n",
    "\n",
    "NOTE: For authentication, a valid .netrc file in the user home ($HOME) directory\\nor a valid appkey is required.\n",
    "\n",
    "    Example .netrc:\n",
    "    machine urs.earthdata.nasa.gov login USERNAME password PASSWD\\n\n",
    "\n",
    "    An appkey can be obtained from:\n",
    "    https://oceandata.sci.gsfc.nasa.gov/appkey/\n",
    "'''\n",
    "    ))\n",
    "    parser.add_argument('-v', '--verbose', help='print status messages',\n",
    "                        action='count',default=0)\n",
    "    parser.add_argument('filename', nargs='?', help='name of the file (or the URL of the file) to retreive')\n",
    "    parser.add_argument('--filelist',\n",
    "                        help='file containing list of filenames to retreive, one per line')\n",
    "    parser.add_argument('--http_manifest',\n",
    "                        help='URL to http_manifest file for OB.DAAC data order')\n",
    "    parser.add_argument('--odir',\n",
    "                        help='full path to desired output directory; \\ndefaults to current working directory: %s' % Path.cwd(),\n",
    "                        default=Path.cwd())\n",
    "    parser.add_argument('--uncompress',action=\"store_true\",\n",
    "                        help='uncompress the retrieved files (if compressed)',\n",
    "                        default=False)\n",
    "    parser.add_argument('--checksum',action=\"store_true\",\n",
    "                        help='compare retrieved file checksum; cannot be used with --uncompress',\n",
    "                        default=False)\n",
    "    parser.add_argument('--failed',help='filename to contain list of files that failed to be retrieved')\n",
    "    parser.add_argument('--appkey',help='value of the users application key')\n",
    "    parser.add_argument('--force',action='store_true',\n",
    "                        help='force download even if file already exists locally',\n",
    "                        default=False)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    filelist = []\n",
    "\n",
    "    if args.http_manifest:\n",
    "        status = retrieveURL(args.http_manifest,verbose=args.verbose,force_download=True,appkey=args.appkey)\n",
    "        if status:\n",
    "            print(\"There was a problem retrieving %s (received status %d)\" % (args.http_manifest,status))\n",
    "            sys.exit(\"Bailing out...\")\n",
    "        else:\n",
    "            with open('http_manifest.txt') as flist:\n",
    "                for filename in flist:\n",
    "                    filelist.append(filename.rstrip())\n",
    "    elif args.filename:\n",
    "        filelist.append(args.filename)\n",
    "    elif args.filelist:\n",
    "        with open(os.path.expandvars(args.filelist)) as flist:\n",
    "            for filename in flist:\n",
    "                filelist.append(os.path.expandvars(filename.rstrip()))\n",
    "\n",
    "    if not len(filelist):\n",
    "        parser.print_usage()\n",
    "        sys.exit(\"Please provide a filename (or list file) to retrieve\")\n",
    "\n",
    "    if args.uncompress and args.checksum:\n",
    "        parser.print_usage()\n",
    "        sys.exit(\"--uncompress is incompatible with --checksum\")\n",
    "\n",
    "    outpath = Path.resolve(Path.expanduser(Path(os.path.expandvars(args.odir))))\n",
    "\n",
    "    if args.verbose:\n",
    "        print(\"Output directory: %s\" % outpath)\n",
    "\n",
    "    failed = None\n",
    "    if args.failed:\n",
    "        failed = open(args.failed, 'w')\n",
    "\n",
    "    for request in filelist:\n",
    "        status = retrieveURL(request,localpath=outpath, uncompress=args.uncompress,\n",
    "                             verbose=args.verbose,force_download=args.force,\n",
    "                             appkey=args.appkey,checksum=args.checksum)\n",
    "        if status:\n",
    "            if status == 304:\n",
    "                if args.verbose:\n",
    "                    print(\"%s is not newer than local copy, skipping download\" % request)\n",
    "            else:\n",
    "                print(\"There was a problem retrieving %s (received status %d)\" % (request,status))\n",
    "                if failed:\n",
    "                    failed.write(request)\n",
    "                    failed.write(\"\\n\")\n",
    "\n",
    "    if failed:\n",
    "        failed.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60fb2ea-14c2-4bfa-a6f2-3614edc2eb26",
   "metadata": {},
   "source": [
    "### from 01-01-2023 to 01-01-2024 \n",
    "#### $$$$ Remote sensing 469 nm, 4$$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80692bd-5b47-48e0-9acf-0d34c6565250",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget -q --post-data=\"results_as_file=1&sensor_id=7&dtid=1043&sdate=2023-01-01 00:00:00&edate=2024-12-01 23:59:59&subType=1&prod_id=Rrs_469&resolution_id=4km&period=DAY\" -O - https://oceandata.sci.gsfc.nasa.gov/api/file_search\n",
    "curl -d \"results_as_file=1&sensor_id=7&dtid=1043&sdate=2023-01-01 00:00:00&edate=2024-12-01 23:59:59&subType=1&prod_id=Rrs_469&resolution_id=4km&period=DAY\" https://oceandata.sci.gsfc.nasa.gov/api/file_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a79c2-5ce3-4548-b16c-cfeaa77686a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ee8bc-0d81-45b7-830d-7da145985b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580c549-fb6f-4359-a240-bb9f0369773e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b81c58-b837-42bf-8164-0103984b88b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
